#!/usr/bin/env python

import sys
from lxml import html
import requests
import time
from random import shuffle
import networkx as nx
import argparse
import threading
import Queue
import re
from datetime import datetime

from signal import *

import gp

class Extend(gp.Worker):

    def __init__(self, exitnode, pool):
        gp.Worker.__init__(self, exitnode.fingerprint, pool)
        self.__pool = pool
        self.__exitnode = exitnode

        print ("%s: Performing test request" % (exitnode.fingerprint))
        try:
            unused = self.request('https://play.google.com/store/apps/details?id=com.whatsapp', sleep = False)
        except KeyboardInterrupt: raise
        except: pass

    def similar(self, package):

        page = self.request('https://play.google.com/store/apps/details?id=%s' % (package))
        if not page:
            return False

        tree = html.fromstring(page.content)

        # Get similar apps
        more = tree.xpath(".//a[text()='Similar']")
        if not more:
            return False

        moreurl = more[0].attrib['href']

        # Get clp= value
        if moreurl:
            clpmatch = re.search('\?clp=(.*)$', moreurl)
            if not clpmatch:
                clp = 'invalid:' + moreurl
            else:
                clp = clpmatch.group(1)
        else:
            clp = 'none'

        # Get category
        cat = tree.cssselect('.category')
        if cat:
            caturl = cat[0].attrib['href']
            catmatch = re.search('\/store\/apps\/category\/(.*)', caturl)
            if catmatch:
                category = catmatch.group(1)
            else:
                category = 'CAT_INVALID:%s' % (caturl)
        else:
            category = 'CAT_NONE'


        page = self.request('https://play.google.com/%s' % (moreurl))
        if page:
            tree = html.fromstring(page.content)
            # FIXME: Use xpath to select cards
            similar_packages = set([card.attrib['data-docid'] for card in tree.cssselect('.card')])
        else:
            similar_packages = set([])

        self.__pool.get_graph()
        self.__pool.store_attribs(package, exitnode = self.__exitnode, clp = clp, category = category)
        self.__pool.store_similar(package, similar_packages)
        self.__pool.put_graph()
        return True

    def run(self):
        while True:
            try:
                next_elem = self.__pool.get_elem()
                self.__pool.done_elem()
                similar = self.similar(next_elem)
                if not similar:
                    self.__pool.put_elem(next_elem)
            except: pass

class Stats(threading.Thread):

    def __init__(self, pool):

        # Initialize threading
        threading.Thread.__init__(self)

        self.__pool = pool

    def run(self):

        last_packages = 0
        queue_last = 0
        start_packages = nx.number_of_nodes(self.__pool.graph())
        start_time = time.time()
        last_checkpoint = start_time
        queue_start = self.__pool.get_queuelen()

        while True:
            current_packages = nx.number_of_nodes(self.__pool.graph())
            new_packages =  current_packages - last_packages
            since_start = current_packages - start_packages
            run_time = (time.time() - start_time)/60

            queue_current = self.__pool.get_queuelen()
            queue_done = queue_last - queue_current
            queue_since_start = queue_start - queue_current

            print("[%s] packages: %d, %d since start (%2.1f per min), %d new | queue: %d, %d done, %d since start (%2.1f per min) | threads: %d" % (str(datetime.now()), current_packages, since_start, since_start/run_time, new_packages, queue_current, queue_done, queue_since_start, queue_since_start/run_time, self.__pool.get_numthreads()))
            last_packages = current_packages
            queue_last = queue_current

            # Write checkpoint every 2 hours
            if time.time() - last_checkpoint > 2 * 60 * 60:
                print("Checkpointing...")
                self.__pool.write()
                last_checkpoint = time.time()

            time.sleep(10)

class Request(gp.TorPool):

    def __init__(self, graphfile):

        self.__graph = nx.DiGraph()
        self.__graphfile = graphfile
        self.__graphlock = threading.Lock()
        self.__queue = Queue.Queue()

    def graph(self):
        return self.__graph

    def get_queuelen(self):
        return self.__queue.qsize()

    def get_elem(self):
        return self.__queue.get()

    def done_elem(self):
        return self.__queue.task_done()

    def put_elem(self, elem):
        self.__queue.put(elem)

    def get_graph(self):
        self.__graphlock.acquire()

    def put_graph(self):
        self.__graphlock.release()

    def bootstrap(self, infile):
        print ("Bootstrapping graph from %s" % (infile))
        self.get_graph()
        self.__graph = nx.read_adjlist(infile)
        self.put_graph()
        print ("Read %d nodes" % (nx.number_of_nodes(self.__graph)))

    def read(self):

        print ("Reading graph from %s" % (self.__graphfile))
        self.get_graph()

        self.__graph = nx.read_adjlist(self.__graphfile + ".adjl")

        with open(self.__graphfile + ".meta", 'r') as meta:
            for line in meta:
                (package, fingerprint, address, clp, category) = line.split()
                self.__graph.nodes[package].update({'fingerprint': fingerprint, 'ipv4address': address, 'clp': clp, 'category': category})

        self.put_graph()
        print ("Read %d nodes" % (nx.number_of_nodes(self.__graph)))

    def write(self):

        print ("Writing graph to %s" % (self.__graphfile))
        self.get_graph()

        nx.write_adjlist(self.__graph, self.__graphfile + ".adjl")

        with open(self.__graphfile + ".meta", 'w') as meta:
            for package in self.__graph.nodes:
                p = self.__graph.nodes[package]
                if 'fingerprint' in p:
                    meta.write("%s %s %s %s %s\n" % (package, p['fingerprint'], p['ipv4address'], p['clp'], p['category']))

        self.put_graph()
        print ("Wrote %d nodes" % (nx.number_of_nodes(self.__graph)))

    def write_gexf(self, outfile):
        import networkx.readwrite.gexf as gexf
        print ("Writing GEXT graph to %s" % (outfile))
        self.get_graph()
        gexf.write_gexf(self.__graph, outfile)
        self.put_graph()

    def write_gml(self, outfile):
        import networkx.readwrite.gml as gml
        print ("Writing GML graph to %s" % (outfile))
        self.get_graph()
        gml.write_gml(self.__graph, outfile)
        self.put_graph()

    def write_graphml(self, outfile):
        import networkx.readwrite.graphml as graphml
        print ("Writing GraphML graph to %s" % (outfile))
        self.get_graph()
        graphml.write_graphml(self.__graph, outfile)
        self.put_graph()

    def store_attribs(self, package, exitnode, clp, category):

        self.__graph.nodes[package].update({'fingerprint': exitnode.fingerprint, 'ipv4address': exitnode.address, 'clp': clp, 'category': category})

    def store_similar(self, package, similar_packages):

        for similar_package in similar_packages:
            if not similar_package in self.__graph.nodes:
                self.put_elem(similar_package)
            self.__graph.add_edge(package, similar_package)

    def enqueue(self, rescan):

        # Skip nodes which already have similar packages, unless we rescan everything
        all_nodes = [node for node in nx.nodes(self.__graph) if rescan or not 'fingerprint' in self.__graph.nodes[node]]
        shuffle(all_nodes)

        for node in all_nodes:
            self.put_elem(node)

        print ("Extending, %d nodes" % (len(all_nodes)))

r = None

def cleanup(*args):
    global r
    print("Aborting, cleaning up.")
    r.write()
    print("Done.")
    sys._exit(1)

def main():

    global r

    parser = argparse.ArgumentParser(description = 'Play Store Website Crawler')
    parser.add_argument('-g', '--graph', action='store', required='True', help='Graph file')
    parser.add_argument('-r', '--rescan', action='store_true', help='Rescan all nodes')
    parser.add_argument('-b', '--bootstrap', action='store', help='Bootstrap list')
    parser.add_argument('-E', '--gexf', action='store', help='Output to GEXF file')
    parser.add_argument('-M', '--gml', action='store', help='Output to GML file')
    parser.add_argument('-R', '--graphml', action='store', help='Output to GraphML file')
    args = parser.parse_args()

    r = Request(args.graph)

    if args.bootstrap:
        r.bootstrap(args.bootstrap)
    else:
        r.read()

    r.enqueue(args.rescan)

    if args.gexf:
        r.write_gexf(args.gexf)

    if args.gml:
        r.write_gml(args.gml)

    if args.graphml:
        r.write_graphml(args.graphml)

    if args.gexf or args.gml or args.graphml:
        sys.exit(0)

    try:
        r.start(Extend, Stats)
    except Exception as e:
        print("main: %s" % (str(e)))
        raise
    finally:
        r.write()
        sys.exit(1)

if __name__ == '__main__':

    for sig in (SIGABRT, SIGTERM, SIGHUP, SIGUSR1, SIGUSR2):
        signal(sig, cleanup)
    main()
