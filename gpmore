#!/usr/bin/env python

import sys
from lxml import html
import requests
import time
from random import shuffle
import networkx as nx
import argparse
import threading
import Queue

import gp

class Extend(gp.Worker):

    def __init__(self, exitnode, pool):
        gp.Worker.__init__(self, exitnode, pool)
        self.__pool = pool

        print ("%s: Performing test request" % (exitnode))
        unused = self.request('https://play.google.com/store/apps/details?id=com.whatsapp')

    def similar(self, package):

        page = self.request('https://play.google.com/store/apps/details?id=%s' % (package))
        if not page:
            return False

        tree = html.fromstring(page.content)
        more = tree.cssselect('.see-more')
        if not more:
            return False

        moreurl = more[0].attrib['href']
        page = self.request('https://play.google.com/%s' % (moreurl))
        if not page:
            return False
        tree = html.fromstring(page.content)

        similar_packages = set([card.attrib['data-docid'] for card in tree.cssselect('.card')])
        self.__pool.store_similar(package, similar_packages)
        return True

    def run(self):
        while True:
            next_elem = self.__pool.get_elem()
            #print("%s: Querying %s" % (self.exitnode(), next_elem))
            self.__pool.done_elem()
            if not self.similar(next_elem):
                self.__pool.put_elem(next_elem)

class Stats(threading.Thread):

    def __init__(self, pool):

        # Initialize threading
        threading.Thread.__init__(self)

        self.__pool = pool

    def run(self):

        last_packages = 0
        start_packages = nx.number_of_nodes(self.__pool.graph())
        start_time = time.time()

        while True:
            current_packages = nx.number_of_nodes(self.__pool.graph())
            new_packages =  current_packages - last_packages
            since_start = current_packages - start_packages
            run_time = (time.time() - start_time)/60

            print("...... %d packages, %d since start (%2.1f per min), %d new, %d per min | queue: %d, threads: %d" % (current_packages, since_start, since_start/run_time, new_packages, new_packages * 6, self.__pool.get_queuelen(), self.__pool.get_numthreads()))
            last_packages = current_packages
            time.sleep(10)

class Request(gp.TorPool):

    def __init__(self, graphfile):

        self.__graph = nx.DiGraph()
        self.__graphfile = graphfile
        self.__graphlock = threading.Lock()
        self.__queue = Queue.Queue()

    def graph(self):
        return self.__graph

    def get_queuelen(self):
        return self.__queue.qsize()

    def get_elem(self):
        return self.__queue.get()

    def done_elem(self):
        return self.__queue.task_done()

    def put_elem(self, elem):
        self.__queue.put(elem)

    def bootstrap(self, infile):
        print ("Bootstrapping graph from %s" % (infile))
        with open(infile, 'r') as f:
            for node in set([x.strip() for x in f.readlines()]):
                self.__graph.add_node(node)

    def read(self):
        print ("Reading graph from %s" % (self.__graphfile))
        self.__graph = nx.read_adjlist(self.__graphfile)
        print ("Read %d nodes" % (nx.number_of_nodes(self.__graph)))

    def write(self):
        self.__graphlock.acquire()
        print ("Writing graph to %s" % (self.__graphfile))
        nx.write_adjlist(self.__graph, self.__graphfile)
        print ("Wrote %d nodes" % (nx.number_of_nodes(self.__graph)))

    def write_gexf(self, outfile):
        import networkx.readwrite.gexf as gexf
        print ("Writing GEXT graph to %s" % (outfile))
        gexf.write_gexf(self.__graph, outfile)

    def write_gml(self, outfile):
        import networkx.readwrite.gml as gml
        print ("Writing GML graph to %s" % (outfile))
        gml.write_gml(self.__graph, outfile)

    def write_graphml(self, outfile):
        import networkx.readwrite.graphml as graphml
        print ("Writing GraphML graph to %s" % (outfile))
        graphml.write_graphml(self.__graph, outfile)

    def store_similar(self, package, similar_packages):

        self.__graphlock.acquire()
        for similar_package in similar_packages:
            self.__graph.add_edge(package, similar_package)
        self.__graphlock.release()

    def enqueue(self, rescan):

        all_nodes = nx.nodes(self.__graph)
        for node in all_nodes:

            # Skip nodes which already have similar packages, unless we rescan everything
            if not rescan and len(self.__graph.edges(nbunch=[node])) > 0:
                continue

            self.put_elem(node)

        print ("Extending, %d nodes" % (len(all_nodes)))

def main():

    parser = argparse.ArgumentParser(description = 'Play Store Website Crawler')
    parser.add_argument('-g', '--graph', action='store', required='True', help='Graph file')
    parser.add_argument('-r', '--rescan', action='store_true', help='Rescan all nodes')
    parser.add_argument('-b', '--bootstrap', action='store', help='Bootstrap list')
    parser.add_argument('-E', '--gexf', action='store', help='Output to GEXF file')
    parser.add_argument('-M', '--gml', action='store', help='Output to GML file')
    parser.add_argument('-R', '--graphml', action='store', help='Output to GraphML file')
    args = parser.parse_args()

    r = Request(args.graph)
    if args.bootstrap:
        r.bootstrap(args.bootstrap)
    else:
        r.read()

    r.enqueue(args.rescan)

    if args.gexf:
        r.write_gexf(args.gexf)

    if args.gml:
        r.write_gml(args.gml)

    if args.graphml:
        r.write_graphml(args.graphml)

    if args.gexf or args.gml or args.graphml:
        sys.exit(0)

    try:
        r.start(Extend, Stats)
    except Exception as e: raise
    finally:
        r.write()
        sys.exit(0)

if __name__ == '__main__':
    main()
