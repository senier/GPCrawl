#!/usr/bin/env python
import sys
import psycopg2
import datetime
import locale
import string
import time
import argparse
import urllib2
import threading
from random import shuffle
from datetime import timedelta

from stem import Signal
from stem.control import Controller

sys.path.append ('googleplay_api')
from googleplay import GooglePlayAPI, LoginError

def enumchar (level, aset):
    if level < 2: return aset
    return [val + newval for newval in aset for val in enumchar(level-1,aset)]

class Terminate(Exception): pass

class GPAPI:

    def __init__(self, androidid, tokenurl, delay = 0, verbose = False):

        self.androidid = androidid
        self.tokenurl  = tokenurl
        self.verbose   = verbose
        self.delay     = delay

        self.controller = Controller.from_socket_file()
        self.controller.authenticate()

        if self.verbose:
            print ("[gpapi] Tor version %s" % self.controller.get_version())

        # Create new circuits
        newnym_delay = self.controller.get_newnym_wait()
        if self.verbose:
            print ("[gpapi] Waiting %d sec until NEWNYM" % newnym_delay)
        time.sleep(newnym_delay + 5)
        self.controller.signal(Signal.NEWNYM)

        # Set locale such that parsing of download numbers works. Note, that
        # this must be changed consistently with the lang value below.
        locale.setlocale(locale.LC_ALL, 'en_US.utf8')

        self.api = GooglePlayAPI(androidId = self.androidid, lang = 'en_us')

        if self.verbose:
            print ("[gpapi] Fetching token from '%s'" % (self.tokenurl,))
        self.token = urllib2.urlopen(self.tokenurl).read()
        if self.verbose:
            print ("[gpapi] Logging in with token '%s'" % (self.token))
        self.api.login(None, None, self.token)

    def search(self, query):
        result = self.api.search (query, nb_results=200)
        time.sleep (self.delay)
        return result

class GPCrawl (threading.Thread):

    def __init__(self, api, dbname, user, args, threadid):

        # Initialize threading
        threading.Thread.__init__(self)

        self.threadid = threadid
        self.args = args
        self.verbose = args.verbose

        self.num_unsuccessful = 0

        self.conn = psycopg2.connect('dbname=%s user=%s' % (dbname, user))
        self.cur = self.conn.cursor()

        self.api = api

        if args.destroy:
            self.cur.execute ('DROP TABLE apps');

        # Create database:
        #   sudo -u postgres createdb google_play_test
        table = '''
            CREATE TABLE IF NOT EXISTS apps
            (
                search                              TEXT,
                docid                               TEXT,
                title                               TEXT,
                creator                             TEXT,
                offer_micros                        INTEGER,
                offer_currencyCode                  TEXT,
                offer_formatedAmount                TEXT,
                offer_checkoutFlowRequired          BOOLEAN,
                offer_offerType                     INTEGER,
                details_appDetails_versionCode      INTEGER,
                details_appDetails_installationSize INTEGER,
                details_appDetails_numDownloads     BIGINT,
                details_appDetails_packageName      TEXT,
                details_appDetails_uploadDate       TEXT,
                details_appDetails_file_fileType    INTEGER,
                details_appDetails_file_versionCode INTEGER,
                details_appDetails_file_size        BIGINT,
                aggregateRating_type                INTEGER,
                aggregateRating_starRating          REAL,
                aggregateRating_ratingsCount        INTEGER,
                aggregateRating_oneStarRating       INTEGER,
                aggregateRating_twoStarRating       INTEGER,
                aggregateRating_threeStarRating     INTEGER,
                aggregateRating_fourStarRating      INTEGER,
                aggregateRating_fiveStarRating      INTEGER,
                aggregateRating_commentCount        INTEGER,
                detailsUrl                          TEXT,
                sharesUrl                           TEXT,
                detailsReusable                     BOOLEAN,
                duplicates                          INTEGER,
                crawlDate                           TIMESTAMP,
                PRIMARY KEY(details_appDetails_packageName, details_appDetails_versionCode)
            )
        '''
        self.cur.execute(table)

        cache = '''
            CREATE TABLE IF NOT EXISTS cache
            (
                search      TEXT,
                requests    INTEGER,
                PRIMARY KEY(search)
            )
        '''
        self.cur.execute(cache)

        self.conn.commit()

    def mark_cached(self, searchterm):

        querystring = '''
            INSERT INTO cache VALUES (%s,%s)
                ON CONFLICT (search)
                    DO UPDATE SET requests = cache.requests + 1
        '''
        self.cur.execute(querystring, (searchterm,1))
        self.conn.commit()

        if self.verbose:
            print("[%s]: ........ Marked '%s' as cached" % (self.threadid, searchterm))

    def cached(self, searchterm):

        self.cur.execute('SELECT requests FROM cache WHERE search LIKE %s', (searchterm,))
        result = self.cur.fetchall()
        if result:
            return result[0][0]

        # Not found
        return 0

    def unique_ids(self):

        self.conn.commit()
        self.cur.execute('SELECT count(*) FROM apps')
        result = self.cur.fetchall()
        return result[0][0]

    def check_terminate(self, new):

        if not self.args.terminate:
            return

        if (new > 0):
            self.num_unsuccessful = 0
        else:
            self.num_unsuccessful += 1

        if self.num_unsuccessful > self.args.terminate:
            print ("[%s]: ........ %d unsuccessful attempts to get new app, terminating" % (self.threadid, self.num_unsuccessful,))
            sys.exit(0)

    def search(self, query):

        num_fail = 0
        num_results = 0
        sleeptime = 30

        num_cached = self.cached (query)
        if  num_cached >= self.args.cache:
            if self.verbose:
                print ("[%s]: ........ Cached %d times, not performing query for '%s'" % (self.threadid, num_cached, query))
            self.check_terminate(0)
            return 0

        uids_before = self.unique_ids()

        num_errors = 0
        while True:
            try:
                results = self.api.search (query)
                break
            except Exception as e:
                print ("[%s]: TERMINATING: %s" % (self.threadid, str(e)))
                raise Terminate()
            except IndexError:
                num_errors += 1
                if num_errors > 2: Terminate()
                time.sleep(sleeptime)

        for docs in results.doc:
            for result in docs.child:

                num_results += 1

                ad = result.details.appDetails
                of = result.offer[0]

                upload_date   = datetime.datetime.strptime(ad.uploadDate, "%b %d, %Y")
                num_downloads = locale.atoi(ad.numDownloads.rstrip('+'))
                querystring = '''
                    INSERT INTO apps VALUES
                        (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,
                         %s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,now())
                    ON CONFLICT (details_appDetails_packageName, details_appDetails_versionCode)
                        DO UPDATE
                            SET duplicates = apps.duplicates + 1, crawlDate = now()
                '''

                querydata = \
                    (query,
                     result.docid,
                     result.title,
                     result.creator,
                     of.micros,
                     of.currencyCode,
                     of.formattedAmount,
                     of.checkoutFlowRequired,
                     of.offerType,
                     ad.versionCode,
                     ad.installationSize,
                     num_downloads,
                     ad.packageName,
                     upload_date.date(),
                     ad.file[0].fileType,
                     ad.file[0].versionCode,
                     ad.file[0].size,
                     result.aggregateRating.type,
                     result.aggregateRating.starRating,
                     result.aggregateRating.ratingsCount,
                     result.aggregateRating.oneStarRatings,
                     result.aggregateRating.twoStarRatings,
                     result.aggregateRating.threeStarRatings,
                     result.aggregateRating.fourStarRatings,
                     result.aggregateRating.fiveStarRatings,
                     result.aggregateRating.commentCount,
                     result.detailsUrl,
                     result.shareUrl,
                     result.detailsReusable,
                     0)

                try:
                    self.cur.execute(querystring, querydata)
                except psycopg2.DataError as e:
                    print ("[%s]: ........ Data error: %s" % (self.threadid, str(e)))
                    print ("[%s]: ........ " % (self.threadid, str(querydata)))

        self.conn.commit()
        self.mark_cached(query)

        uids_delta = self.unique_ids() - uids_before
        self.check_terminate(uids_delta)

        if self.verbose:
            print ("[%s]: ........ Searched '%s', got %d results, %d new packages" % (self.threadid, query, num_results, uids_delta))

        return uids_delta

    def search_list(self, queries):

        query_num = 0
        starttime = time.time()
        for query in queries:
            self.search(query)
            query_num += 1
            if self.verbose:
                print ("[%s]: ........ Searching %d/%d: '%s'" % (self.threadid, query_num, len(queries), query))
            self.search(query)
            duration = time.time() - starttime
            if self.verbose:
                time_to_go = (len(queries) - query_num) * query_num / duration
                print ("[%s]: %d unique packages, duration %s seconds, ETA=%s" %
                    (self.threadid, self.unique_ids(), timedelta(seconds=duration), timedelta(seconds=time_to_go)))

    def seed(self, length):
        for run in (1,2):
            self.search_list(enumchar(length, string.ascii_lowercase))

    def extend_creator(self):
        self.cur.execute('SELECT DISTINCT creator FROM apps')
        creators = [creator[0] for creator in self.cur.fetchall()]
        shuffle(creators)
        self.search_list(creators)

    def tokens(self):
        tokens = {}
        self.cur.execute('SELECT title FROM apps')
        result = self.cur.fetchall()
        for (title,) in result:
            for t in title.split():
                t = t.lower()
                if t in tokens:
                    tokens[t] += 1
                else:
                    tokens[t] = 1

        return tokens

    def extend_tokens(self):
        tokens = self.tokens().keys()
        shuffle(tokens)
        self.search_list(tokens)

    def packages(self):
        names = {}
        self.cur.execute('SELECT details_appdetails_packagename FROM apps')
        result = self.cur.fetchall()
        for (pname,) in result:
            plist = pname.split('.')
            for i in range(0, len(plist)):  # Ignore last component as this is the known package!
                psubname = '.'.join(plist[0:i])
                if psubname in names:
                    names[psubname] += 1
                else:
                    names[psubname] = 1

        return names

    def extend_packages(self):
        packages = self.packages().keys()
        shuffle(packages)
        self.search_list(packages)

    def run(self):

        try:

            if self.args.search:
                self.search(self.args.search)

            if self.args.seed_depth:
                self.seed(self.args.seed_depth)

            if self.args.creator:
                self.extend_creator()

            if self.args.packages:
                self.extend_packages()

            if self.args.titles:
                self.extend_titles()

        except Terminate:
            pass

def sledgehammer(args):

    api = GPAPI(androidid  = args.androidid, tokenurl = args.token, verbose = args.verbose)

    threads = []

    for thread_num in range(1, args.parallel+1):
        thread_name = 'thread-%2.2d' % (thread_num)
        gpc = GPCrawl (
            dbname     = args.dbname,
            user       = args.dbuser,
            threadid   = thread_name,
            api        = api,
            args       = args)
        gpc.daemon = True
        threads.append (gpc)
        print ("[main]: Starting %s" % (thread_name,))
        gpc.start()

    for thread in threads:
        thread.join()

def main():

    parser = argparse.ArgumentParser(description = 'Play Store Crawler')
    parser.add_argument('-S', '--seed', action='store', type=int, default=0, dest='seed_depth', help='Do brute force search of depth n')
    parser.add_argument('-X', '--terminate', action='store', type=int, default=0, help='Terminate after n unsuccessful attempts to query new apps')
    parser.add_argument('-C', '--creator', action='store_true', help='Extend database by creator')
    parser.add_argument('-P', '--packages', action='store_true', help='Extend database by package name')
    parser.add_argument('-T', '--titles', action='store_true', help='Extend database by titles')
    parser.add_argument('-D', '--delay', action='store', type=int, default=10, help='Delay between queries (in seconds)')
    parser.add_argument('-s', '--search', action='store', help='Search for term')
    parser.add_argument('-v', '--verbose', action='store_true', default=False, help='Verbose output')
    parser.add_argument('-c', '--cache', action='store', default=2, type=int, help='How often to query before considering data cached')
    parser.add_argument('-t', '--token', action='store', default="file:///etc/gpcrawl/token.dat", help='URL to fetch token from (may be file://)')
    parser.add_argument('-j', '--parallel', action='store', type=int, default=1, help='Start n multiple threads in parallel')
    parser.add_argument('-x', '--destroy', action='store_true', default=False, help='DANGEROUS! Wipe database.')
    parser.add_argument('-d', '--dbuser', action='store', help='Database user to use.')
    parser.add_argument('-n', '--dbname', action='store', help='Database name to use.')
    parser.add_argument('-a', '--androidid', action='store', help='Android ID to use.')
    args = parser.parse_args()

    while True:
        try:
            sledgehammer(args)
        except KeyboardInterrupt: raise
        except: pass
        time.sleep (60)

if __name__ == '__main__':
    main()
